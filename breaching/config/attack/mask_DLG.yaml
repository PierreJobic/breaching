# Deep Leakage from Gradients
defaults:
  - _default_optimization_attack
  - _self_
type: deep-leakage
attack_type: optimization
label_strategy: None

token_recovery: from-embedding

objective:
  type: Masked-euclidean
  scale: 1.0
  task_regularization: 0.0
  mask: 
    type: ???
    p: None
    clip_value: None
    q: None
    layer: None
    # p in [0, 1]
    # clip_value in [0,1]
    # q in [0, 1]
    # layer in list, example: [0] take only the first layer of the DNN

optim:
  optimizer: adam
  step_size: 0.1
  boxed: False
  max_iterations: 2400

  callback: 100 # Print objective value every callback many iterations
